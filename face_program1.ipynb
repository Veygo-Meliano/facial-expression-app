{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e8ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92110c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust', 'sadness', 'happy', 'anger', 'contempt', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "data_path = '/home/vego/Documents/skripsi/program/dataset/CK+48'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "print(data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b1e1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_image = ImageDataGenerator(rescale=1./255,\n",
    "                                validation_split=0.3,\n",
    "                                rotation_range=20,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                zoom_range=0.2,  \n",
    "                                horizontal_flip=True,\n",
    "                                shear_range=0.2,\n",
    "                                fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076f1d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 689 images belonging to 7 classes.\n",
      "Found 292 images belonging to 7 classes.\n",
      "Found 981 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "size = 48\n",
    "batch = 32\n",
    "\n",
    "train_data = aug_image.flow_from_directory(data_path,\n",
    "                                          #color_mode='grayscale',\n",
    "                                          target_size=(size,size),\n",
    "                                          batch_size=batch,\n",
    "                                          class_mode='categorical',\n",
    "                                          subset='training')\n",
    "\n",
    "valid_data = aug_image.flow_from_directory(data_path,\n",
    "                                          #color_mode='grayscale',\n",
    "                                          target_size=(size,size),\n",
    "                                          batch_size=batch,\n",
    "                                          class_mode='categorical',\n",
    "                                          subset='validation',\n",
    "                                          shuffle=False)\n",
    "\n",
    "test_data = aug_image.flow_from_directory(data_path,\n",
    "                                         #color_mode='grayscale',\n",
    "                                         target_size=(size,size),\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e23269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,MaxPool2D,Conv2D,Dropout,MaxPooling2D,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b7f6ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 45, 45, 32)        1568      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 19, 19, 32)        16416     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 9, 9, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 64)          32832     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:25:19.462742: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-08-29 02:25:19.462793: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: vego-VivoBook-14-ASUS-Laptop-X407UB\n",
      "2022-08-29 02:25:19.462807: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: vego-VivoBook-14-ASUS-Laptop-X407UB\n",
      "2022-08-29 02:25:19.462926: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.85.2\n",
      "2022-08-29 02:25:19.462965: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.85.2\n",
      "2022-08-29 02:25:19.462976: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.85.2\n",
      "2022-08-29 02:25:19.464380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 88,199\n",
      "Trainable params: 88,199\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=4,activation=\"relu\",input_shape=(48,48,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=4,activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=4,activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(7,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9432507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278d59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model dengan 'adam' optimize loss function 'binary_crossentropy'\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(learning_rate=0.001),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da9798bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 - 7s - loss: 0.4706 - accuracy: 0.2104 - val_loss: 0.4027 - val_accuracy: 0.2534 - 7s/epoch - 296ms/step\n",
      "Epoch 2/100\n",
      "22/22 - 4s - loss: 0.4156 - accuracy: 0.2163 - val_loss: 0.3966 - val_accuracy: 0.2534 - 4s/epoch - 160ms/step\n",
      "Epoch 3/100\n",
      "22/22 - 4s - loss: 0.4140 - accuracy: 0.2046 - val_loss: 0.3939 - val_accuracy: 0.2534 - 4s/epoch - 165ms/step\n",
      "Epoch 4/100\n",
      "22/22 - 4s - loss: 0.4045 - accuracy: 0.2482 - val_loss: 0.3914 - val_accuracy: 0.2534 - 4s/epoch - 165ms/step\n",
      "Epoch 5/100\n",
      "22/22 - 4s - loss: 0.4034 - accuracy: 0.2467 - val_loss: 0.3905 - val_accuracy: 0.2534 - 4s/epoch - 165ms/step\n",
      "Epoch 6/100\n",
      "22/22 - 3s - loss: 0.3954 - accuracy: 0.2525 - val_loss: 0.3722 - val_accuracy: 0.3425 - 3s/epoch - 158ms/step\n",
      "Epoch 7/100\n",
      "22/22 - 4s - loss: 0.3688 - accuracy: 0.3425 - val_loss: 0.3405 - val_accuracy: 0.3973 - 4s/epoch - 163ms/step\n",
      "Epoch 8/100\n",
      "22/22 - 4s - loss: 0.3419 - accuracy: 0.4107 - val_loss: 0.3215 - val_accuracy: 0.4486 - 4s/epoch - 161ms/step\n",
      "Epoch 9/100\n",
      "22/22 - 3s - loss: 0.3322 - accuracy: 0.4180 - val_loss: 0.3096 - val_accuracy: 0.4795 - 3s/epoch - 158ms/step\n",
      "Epoch 10/100\n",
      "22/22 - 3s - loss: 0.3200 - accuracy: 0.4136 - val_loss: 0.2879 - val_accuracy: 0.5308 - 3s/epoch - 159ms/step\n",
      "Epoch 11/100\n",
      "22/22 - 4s - loss: 0.3063 - accuracy: 0.4601 - val_loss: 0.2962 - val_accuracy: 0.4795 - 4s/epoch - 160ms/step\n",
      "Epoch 12/100\n",
      "22/22 - 4s - loss: 0.2966 - accuracy: 0.4833 - val_loss: 0.2793 - val_accuracy: 0.5308 - 4s/epoch - 170ms/step\n",
      "Epoch 13/100\n",
      "22/22 - 4s - loss: 0.2964 - accuracy: 0.4935 - val_loss: 0.2975 - val_accuracy: 0.5034 - 4s/epoch - 164ms/step\n",
      "Epoch 14/100\n",
      "22/22 - 4s - loss: 0.2825 - accuracy: 0.5225 - val_loss: 0.2645 - val_accuracy: 0.5822 - 4s/epoch - 167ms/step\n",
      "Epoch 15/100\n",
      "22/22 - 4s - loss: 0.2778 - accuracy: 0.5327 - val_loss: 0.2645 - val_accuracy: 0.5925 - 4s/epoch - 173ms/step\n",
      "Epoch 16/100\n",
      "22/22 - 4s - loss: 0.2674 - accuracy: 0.5704 - val_loss: 0.2375 - val_accuracy: 0.6096 - 4s/epoch - 160ms/step\n",
      "Epoch 17/100\n",
      "22/22 - 4s - loss: 0.2608 - accuracy: 0.5806 - val_loss: 0.2375 - val_accuracy: 0.6404 - 4s/epoch - 160ms/step\n",
      "Epoch 18/100\n",
      "22/22 - 3s - loss: 0.2411 - accuracy: 0.6154 - val_loss: 0.2343 - val_accuracy: 0.6507 - 3s/epoch - 158ms/step\n",
      "Epoch 19/100\n",
      "22/22 - 3s - loss: 0.2452 - accuracy: 0.6096 - val_loss: 0.2415 - val_accuracy: 0.6233 - 3s/epoch - 156ms/step\n",
      "Epoch 20/100\n",
      "22/22 - 3s - loss: 0.2305 - accuracy: 0.6183 - val_loss: 0.2279 - val_accuracy: 0.6575 - 3s/epoch - 154ms/step\n",
      "Epoch 21/100\n",
      "22/22 - 3s - loss: 0.2235 - accuracy: 0.6560 - val_loss: 0.2129 - val_accuracy: 0.6678 - 3s/epoch - 156ms/step\n",
      "Epoch 22/100\n",
      "22/22 - 4s - loss: 0.2240 - accuracy: 0.6415 - val_loss: 0.2174 - val_accuracy: 0.6610 - 4s/epoch - 167ms/step\n",
      "Epoch 23/100\n",
      "22/22 - 3s - loss: 0.2201 - accuracy: 0.6531 - val_loss: 0.2045 - val_accuracy: 0.6781 - 3s/epoch - 159ms/step\n",
      "Epoch 24/100\n",
      "22/22 - 3s - loss: 0.2020 - accuracy: 0.6938 - val_loss: 0.1951 - val_accuracy: 0.7123 - 3s/epoch - 157ms/step\n",
      "Epoch 25/100\n",
      "22/22 - 3s - loss: 0.2087 - accuracy: 0.6705 - val_loss: 0.2028 - val_accuracy: 0.6747 - 3s/epoch - 155ms/step\n",
      "Epoch 26/100\n",
      "22/22 - 3s - loss: 0.1971 - accuracy: 0.7039 - val_loss: 0.1975 - val_accuracy: 0.6884 - 3s/epoch - 156ms/step\n",
      "Epoch 27/100\n",
      "22/22 - 4s - loss: 0.1999 - accuracy: 0.6952 - val_loss: 0.1863 - val_accuracy: 0.7192 - 4s/epoch - 160ms/step\n",
      "Epoch 28/100\n",
      "22/22 - 3s - loss: 0.1975 - accuracy: 0.6923 - val_loss: 0.1902 - val_accuracy: 0.6918 - 3s/epoch - 156ms/step\n",
      "Epoch 29/100\n",
      "22/22 - 4s - loss: 0.1888 - accuracy: 0.7126 - val_loss: 0.1849 - val_accuracy: 0.7192 - 4s/epoch - 159ms/step\n",
      "Epoch 30/100\n",
      "22/22 - 4s - loss: 0.1779 - accuracy: 0.7257 - val_loss: 0.1858 - val_accuracy: 0.6986 - 4s/epoch - 160ms/step\n",
      "Epoch 31/100\n",
      "22/22 - 3s - loss: 0.1815 - accuracy: 0.7184 - val_loss: 0.1743 - val_accuracy: 0.7329 - 3s/epoch - 159ms/step\n",
      "Epoch 32/100\n",
      "22/22 - 4s - loss: 0.1805 - accuracy: 0.7083 - val_loss: 0.1698 - val_accuracy: 0.7466 - 4s/epoch - 161ms/step\n",
      "Epoch 33/100\n",
      "22/22 - 3s - loss: 0.1725 - accuracy: 0.7417 - val_loss: 0.1750 - val_accuracy: 0.7192 - 3s/epoch - 135ms/step\n",
      "Epoch 34/100\n",
      "22/22 - 3s - loss: 0.1736 - accuracy: 0.7402 - val_loss: 0.1601 - val_accuracy: 0.7500 - 3s/epoch - 135ms/step\n",
      "Epoch 35/100\n",
      "22/22 - 3s - loss: 0.1813 - accuracy: 0.7242 - val_loss: 0.1921 - val_accuracy: 0.6952 - 3s/epoch - 135ms/step\n",
      "Epoch 36/100\n",
      "22/22 - 3s - loss: 0.1766 - accuracy: 0.7025 - val_loss: 0.1839 - val_accuracy: 0.6952 - 3s/epoch - 132ms/step\n",
      "Epoch 37/100\n",
      "22/22 - 3s - loss: 0.1759 - accuracy: 0.7170 - val_loss: 0.1849 - val_accuracy: 0.6884 - 3s/epoch - 135ms/step\n",
      "Epoch 38/100\n",
      "22/22 - 3s - loss: 0.1562 - accuracy: 0.7678 - val_loss: 0.1905 - val_accuracy: 0.6849 - 3s/epoch - 132ms/step\n",
      "Epoch 39/100\n",
      "22/22 - 3s - loss: 0.1578 - accuracy: 0.7489 - val_loss: 0.1795 - val_accuracy: 0.7260 - 3s/epoch - 131ms/step\n",
      "Epoch 40/100\n",
      "22/22 - 3s - loss: 0.1669 - accuracy: 0.7358 - val_loss: 0.1586 - val_accuracy: 0.7363 - 3s/epoch - 137ms/step\n",
      "Epoch 41/100\n",
      "22/22 - 3s - loss: 0.1565 - accuracy: 0.7707 - val_loss: 0.1657 - val_accuracy: 0.7192 - 3s/epoch - 130ms/step\n",
      "Epoch 42/100\n",
      "22/22 - 3s - loss: 0.1541 - accuracy: 0.7765 - val_loss: 0.1694 - val_accuracy: 0.7226 - 3s/epoch - 133ms/step\n",
      "Epoch 43/100\n",
      "22/22 - 3s - loss: 0.1551 - accuracy: 0.7750 - val_loss: 0.1724 - val_accuracy: 0.7158 - 3s/epoch - 132ms/step\n",
      "Epoch 44/100\n",
      "22/22 - 3s - loss: 0.1507 - accuracy: 0.7736 - val_loss: 0.1517 - val_accuracy: 0.7568 - 3s/epoch - 130ms/step\n",
      "Epoch 45/100\n",
      "22/22 - 3s - loss: 0.1470 - accuracy: 0.7721 - val_loss: 0.1446 - val_accuracy: 0.7808 - 3s/epoch - 135ms/step\n",
      "Epoch 46/100\n",
      "22/22 - 3s - loss: 0.1525 - accuracy: 0.7547 - val_loss: 0.1834 - val_accuracy: 0.6918 - 3s/epoch - 139ms/step\n",
      "Epoch 47/100\n",
      "22/22 - 3s - loss: 0.1475 - accuracy: 0.7852 - val_loss: 0.1551 - val_accuracy: 0.7671 - 3s/epoch - 138ms/step\n",
      "Epoch 48/100\n",
      "22/22 - 3s - loss: 0.1395 - accuracy: 0.8055 - val_loss: 0.1550 - val_accuracy: 0.7979 - 3s/epoch - 135ms/step\n",
      "Epoch 49/100\n",
      "22/22 - 3s - loss: 0.1393 - accuracy: 0.7852 - val_loss: 0.1605 - val_accuracy: 0.7603 - 3s/epoch - 133ms/step\n",
      "Epoch 50/100\n",
      "22/22 - 3s - loss: 0.1504 - accuracy: 0.7794 - val_loss: 0.1634 - val_accuracy: 0.7637 - 3s/epoch - 130ms/step\n",
      "Epoch 51/100\n",
      "22/22 - 4s - loss: 0.1372 - accuracy: 0.7896 - val_loss: 0.1544 - val_accuracy: 0.7911 - 4s/epoch - 163ms/step\n",
      "Epoch 52/100\n",
      "22/22 - 3s - loss: 0.1399 - accuracy: 0.7881 - val_loss: 0.1598 - val_accuracy: 0.7226 - 3s/epoch - 137ms/step\n",
      "Epoch 53/100\n",
      "22/22 - 3s - loss: 0.1297 - accuracy: 0.8244 - val_loss: 0.1616 - val_accuracy: 0.7466 - 3s/epoch - 132ms/step\n",
      "Epoch 54/100\n",
      "22/22 - 3s - loss: 0.1397 - accuracy: 0.7925 - val_loss: 0.1363 - val_accuracy: 0.7911 - 3s/epoch - 133ms/step\n",
      "Epoch 55/100\n",
      "22/22 - 3s - loss: 0.1224 - accuracy: 0.8142 - val_loss: 0.1404 - val_accuracy: 0.7945 - 3s/epoch - 134ms/step\n",
      "Epoch 56/100\n",
      "22/22 - 3s - loss: 0.1233 - accuracy: 0.8331 - val_loss: 0.1474 - val_accuracy: 0.7568 - 3s/epoch - 138ms/step\n",
      "Epoch 57/100\n",
      "22/22 - 3s - loss: 0.1177 - accuracy: 0.8491 - val_loss: 0.1437 - val_accuracy: 0.8014 - 3s/epoch - 136ms/step\n",
      "Epoch 58/100\n",
      "22/22 - 4s - loss: 0.1241 - accuracy: 0.8186 - val_loss: 0.1346 - val_accuracy: 0.8151 - 4s/epoch - 160ms/step\n",
      "Epoch 59/100\n",
      "22/22 - 3s - loss: 0.1214 - accuracy: 0.8433 - val_loss: 0.1357 - val_accuracy: 0.7979 - 3s/epoch - 156ms/step\n",
      "Epoch 60/100\n",
      "22/22 - 3s - loss: 0.1200 - accuracy: 0.8084 - val_loss: 0.1385 - val_accuracy: 0.8082 - 3s/epoch - 152ms/step\n",
      "Epoch 61/100\n",
      "22/22 - 3s - loss: 0.1195 - accuracy: 0.8258 - val_loss: 0.1489 - val_accuracy: 0.7568 - 3s/epoch - 147ms/step\n",
      "Epoch 62/100\n",
      "22/22 - 3s - loss: 0.1325 - accuracy: 0.8041 - val_loss: 0.1386 - val_accuracy: 0.7877 - 3s/epoch - 133ms/step\n",
      "Epoch 63/100\n",
      "22/22 - 3s - loss: 0.1246 - accuracy: 0.8186 - val_loss: 0.1296 - val_accuracy: 0.8116 - 3s/epoch - 129ms/step\n",
      "Epoch 64/100\n",
      "22/22 - 3s - loss: 0.1155 - accuracy: 0.8345 - val_loss: 0.1412 - val_accuracy: 0.7808 - 3s/epoch - 139ms/step\n",
      "Epoch 65/100\n",
      "22/22 - 3s - loss: 0.1147 - accuracy: 0.8403 - val_loss: 0.1363 - val_accuracy: 0.7671 - 3s/epoch - 135ms/step\n",
      "Epoch 66/100\n",
      "22/22 - 3s - loss: 0.1107 - accuracy: 0.8229 - val_loss: 0.1260 - val_accuracy: 0.8151 - 3s/epoch - 138ms/step\n",
      "Epoch 67/100\n",
      "22/22 - 3s - loss: 0.1048 - accuracy: 0.8534 - val_loss: 0.1304 - val_accuracy: 0.7945 - 3s/epoch - 156ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "22/22 - 3s - loss: 0.1070 - accuracy: 0.8433 - val_loss: 0.1258 - val_accuracy: 0.8151 - 3s/epoch - 146ms/step\n",
      "Epoch 69/100\n",
      "22/22 - 3s - loss: 0.1126 - accuracy: 0.8244 - val_loss: 0.1298 - val_accuracy: 0.7979 - 3s/epoch - 143ms/step\n",
      "Epoch 70/100\n",
      "22/22 - 5s - loss: 0.1079 - accuracy: 0.8462 - val_loss: 0.1462 - val_accuracy: 0.7671 - 5s/epoch - 213ms/step\n",
      "Epoch 71/100\n",
      "22/22 - 3s - loss: 0.1114 - accuracy: 0.8273 - val_loss: 0.1431 - val_accuracy: 0.7774 - 3s/epoch - 134ms/step\n",
      "Epoch 72/100\n",
      "22/22 - 3s - loss: 0.1062 - accuracy: 0.8621 - val_loss: 0.1342 - val_accuracy: 0.7774 - 3s/epoch - 135ms/step\n",
      "Epoch 73/100\n",
      "22/22 - 3s - loss: 0.1026 - accuracy: 0.8621 - val_loss: 0.1236 - val_accuracy: 0.8322 - 3s/epoch - 137ms/step\n",
      "Epoch 74/100\n",
      "22/22 - 3s - loss: 0.1076 - accuracy: 0.8462 - val_loss: 0.1224 - val_accuracy: 0.8219 - 3s/epoch - 130ms/step\n",
      "Epoch 75/100\n",
      "22/22 - 3s - loss: 0.1039 - accuracy: 0.8650 - val_loss: 0.1269 - val_accuracy: 0.8425 - 3s/epoch - 130ms/step\n",
      "Epoch 76/100\n",
      "22/22 - 3s - loss: 0.1039 - accuracy: 0.8505 - val_loss: 0.1175 - val_accuracy: 0.8425 - 3s/epoch - 133ms/step\n",
      "Epoch 77/100\n",
      "22/22 - 3s - loss: 0.1027 - accuracy: 0.8447 - val_loss: 0.1307 - val_accuracy: 0.8253 - 3s/epoch - 129ms/step\n",
      "Epoch 78/100\n",
      "22/22 - 3s - loss: 0.1004 - accuracy: 0.8592 - val_loss: 0.1392 - val_accuracy: 0.8116 - 3s/epoch - 138ms/step\n",
      "Epoch 79/100\n",
      "22/22 - 3s - loss: 0.1075 - accuracy: 0.8563 - val_loss: 0.1381 - val_accuracy: 0.7979 - 3s/epoch - 135ms/step\n",
      "Epoch 80/100\n",
      "22/22 - 3s - loss: 0.1038 - accuracy: 0.8534 - val_loss: 0.1286 - val_accuracy: 0.8185 - 3s/epoch - 131ms/step\n",
      "Epoch 81/100\n",
      "22/22 - 3s - loss: 0.0966 - accuracy: 0.8723 - val_loss: 0.1200 - val_accuracy: 0.8253 - 3s/epoch - 135ms/step\n",
      "Epoch 82/100\n",
      "22/22 - 3s - loss: 0.0947 - accuracy: 0.8781 - val_loss: 0.1481 - val_accuracy: 0.8014 - 3s/epoch - 130ms/step\n",
      "Epoch 83/100\n",
      "22/22 - 3s - loss: 0.1105 - accuracy: 0.8462 - val_loss: 0.1417 - val_accuracy: 0.7945 - 3s/epoch - 137ms/step\n",
      "Epoch 84/100\n",
      "22/22 - 3s - loss: 0.0960 - accuracy: 0.8781 - val_loss: 0.1275 - val_accuracy: 0.8288 - 3s/epoch - 133ms/step\n",
      "Epoch 85/100\n",
      "22/22 - 3s - loss: 0.0924 - accuracy: 0.8824 - val_loss: 0.1337 - val_accuracy: 0.8425 - 3s/epoch - 128ms/step\n",
      "Epoch 86/100\n",
      "22/22 - 3s - loss: 0.1010 - accuracy: 0.8505 - val_loss: 0.1145 - val_accuracy: 0.8322 - 3s/epoch - 135ms/step\n",
      "Epoch 87/100\n",
      "22/22 - 3s - loss: 0.0888 - accuracy: 0.8795 - val_loss: 0.1319 - val_accuracy: 0.8116 - 3s/epoch - 134ms/step\n",
      "Epoch 88/100\n",
      "22/22 - 3s - loss: 0.0838 - accuracy: 0.8911 - val_loss: 0.1250 - val_accuracy: 0.8151 - 3s/epoch - 132ms/step\n",
      "Epoch 89/100\n",
      "22/22 - 3s - loss: 0.0783 - accuracy: 0.8926 - val_loss: 0.1408 - val_accuracy: 0.8048 - 3s/epoch - 133ms/step\n",
      "Epoch 90/100\n",
      "22/22 - 3s - loss: 0.1059 - accuracy: 0.8534 - val_loss: 0.1352 - val_accuracy: 0.8219 - 3s/epoch - 133ms/step\n",
      "Epoch 91/100\n",
      "22/22 - 3s - loss: 0.0918 - accuracy: 0.8723 - val_loss: 0.1322 - val_accuracy: 0.7808 - 3s/epoch - 142ms/step\n",
      "Epoch 92/100\n",
      "22/22 - 3s - loss: 0.0917 - accuracy: 0.8636 - val_loss: 0.1123 - val_accuracy: 0.8527 - 3s/epoch - 134ms/step\n",
      "Epoch 93/100\n",
      "22/22 - 3s - loss: 0.0972 - accuracy: 0.8607 - val_loss: 0.1075 - val_accuracy: 0.8527 - 3s/epoch - 133ms/step\n",
      "Epoch 94/100\n",
      "22/22 - 3s - loss: 0.0889 - accuracy: 0.8781 - val_loss: 0.1368 - val_accuracy: 0.8048 - 3s/epoch - 136ms/step\n",
      "Epoch 95/100\n",
      "22/22 - 3s - loss: 0.0812 - accuracy: 0.8955 - val_loss: 0.1097 - val_accuracy: 0.8219 - 3s/epoch - 135ms/step\n",
      "Epoch 96/100\n",
      "22/22 - 3s - loss: 0.0811 - accuracy: 0.8940 - val_loss: 0.1302 - val_accuracy: 0.8219 - 3s/epoch - 137ms/step\n",
      "Epoch 97/100\n",
      "22/22 - 3s - loss: 0.0937 - accuracy: 0.8868 - val_loss: 0.1341 - val_accuracy: 0.7945 - 3s/epoch - 143ms/step\n",
      "Epoch 98/100\n",
      "22/22 - 3s - loss: 0.0860 - accuracy: 0.8868 - val_loss: 0.1362 - val_accuracy: 0.8253 - 3s/epoch - 140ms/step\n",
      "Epoch 99/100\n",
      "22/22 - 3s - loss: 0.0885 - accuracy: 0.8752 - val_loss: 0.1100 - val_accuracy: 0.8699 - 3s/epoch - 140ms/step\n",
      "Epoch 100/100\n",
      "22/22 - 3s - loss: 0.0901 - accuracy: 0.8824 - val_loss: 0.1215 - val_accuracy: 0.8219 - 3s/epoch - 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1983fa7400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_model = 'my_model.h5'\n",
    "\n",
    "# checkpoint = ModelCheckpoint(save_model, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "# callback_list=[checkpoint]\n",
    "\n",
    "# latih model dengan model.fit\n",
    "hist = model.fit(train_data,\n",
    "          batch_size=batch,\n",
    "          epochs=100, # tambahkan epoch jika akurasi model belum optimal\n",
    "          validation_data=valid_data,\n",
    "          #callbacks=callback_list,\n",
    "          verbose=2)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4072c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f0f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/vego/Documents/skripsi/program/my_model.h5'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b1a1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "/home/vego/Documents/skripsi/program/dataset/uji/angry/S026_003_00000013.png\n",
      "Angry\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAea0lEQVR4nO2dbYimV3nH/9euicmaxH2dndndbHcla41IqxCswX6QxEBqxUhB0GLZQmC/tJBQi9m0UPBDYUtB/NB+WVDcoihChIRgkSVtqKKo0USbNC+bl25edjL7romJefP0wzy7ned//jP3NffMPs+znv8Plplz9tz3fe5z39c8c/3nuq4TpRQYY373WTPuCRhjRoON3ZhGsLEb0wg2dmMawcZuTCPY2I1phBUZe0TcHBGPR8STEbF/tSZljFl9ou/f2SNiLYAnANwE4HkAPwHwmVLK/yxxTImIrvN29q1ZU/+Metvb3jbUvuyyy6oxa9euXfIY1cfHqOurOas5qr5RoZ5z17PIknlm6vrc99vf/rZzjCJznjfeeGOo/eabb1Zj3nrrrarvtdde6zyOr6fOw3NU93XppZcu2c7w6quv4vXXX5cPtn7b83wQwJOllKcBICK+CeAWAEsZOy655JIlT6pu8O1vf3vnmOnp6aH2NddcU43ZsGHDUHvTpk3VmKmpqaH2VVdd1TlH9YPlHe94R9XH96F+kPQhYyRqDBukmk/mh4T6ocnnUtdnQ3rllVeqMWykaj5sXL/+9a+rMS+++OJQ+/Tp09UY1Xf06NGh9tzcXDWG562uz/eqfiBs3759qL1z585qTNcP6B/84AeL/t9KPmq2A3huQfv5QZ8xZgJZySe7+hFT/diNiH0A9q3gOsaYVWAlxv48gKsXtHcAOMaDSikHARwEgDVr1jgQ35gxsRJj/wmAPRGxG8ALAD4N4M+XexIWrZTfyH7K5ZdfXo1h/1v5zOxrKz/ypZdeGmorjYHPo/xI9jWBnNDYdcxifUxGEGKU+JQRHzNiZEY0U34s96l17SN+qXdIvTPr168faitdITPH119/vXOO7NerMSsReXsbeynlzYj4awDfBbAWwFdKKY/0nokx5oKykk92lFK+A+A7qzQXY8wFxBF0xjTCij7Zl0sppfLdMj4Ij7nyyiurMfz3cOX787XZRwJq306NYf9L/Z1ZHce+nTquz3oov1r5yH1Q52Zf8je/+U3qOIY1AqUZZMbwWmf8+kxgFgBcccUVQ2324YHaj1fX52efiRdQGga/18sJivMnuzGNYGM3phFs7MY0go3dmEYYqUAXEZXA0EeQyiSZZBIv1BgWaVTwBQt02ewkvnd1XCaDKiP2ZIQtDhjKJuZkAqF4jhlhLZMtpt4XHsPPR/Wp+SiBjp+/eh/43VPnYcFSCZg8J7UefQTu82PTI40xFzU2dmMawcZuTCOM1GcHupMWMoEVq3Vt5RNxQIQKGGH/TwVRKNhPU0kVPMe+iR98b32ryWT8cTXHPuuYSahRwUqvvvrqkucF6ndI6TXq+uyPcxvIBbpkAmb66CwOqjHGVNjYjWkEG7sxjWBjN6YRRi7QMSyUKMGBgxQywSiZqqiZCjMs/gC12KSEHTXHjJDDc8wEmmQy0zIBM9nqsn1KN6uKqxmBjlECHV9fCVs8n0xwDqDXn+HrZQTbzLt38uTJagwHlHGQz1LZjv5kN6YRbOzGNIKN3ZhGGHulmszuIrzjSmZ3kwyZoBrls585c2bJYwAdfJEJhskkTGSSIbhPaQiZarcqQCUzR14TdZ5MdVlGPfuMz8xrrd6zjM+eqfia0T7UWvO98XsG1JVyuGrTUrqHP9mNaQQbuzGNYGM3phFs7MY0wsgr1WTEHSYjwHCwhRIqWOjLlHJWggyLTSpgRAV2ZIJGMts699n7XK1ZRuhTz4fXLRPEkqneokS8TFZXn220stliLGyuW7euc0xmD/eMQKdYSQaoP9mNaQQbuzGNYGM3phFGHlTT5SspvyVTPTSz1XImiCSzHXHG/8ts3aP82EzST0ZXYN9OrVnfLaP5PpSukLkPnqOqZsNjMhqKGtMVzAXoZ8b3oSobb968eaittifje8tUDc6857w9lRNhjDE2dmNawcZuTCPY2I1phJFXqumqKKNEKxYuVAlm3p9dBZGwSKLEFhabMlVgFJlgFCVaZQQhFtaUkMNkxCdFZossJYZm9pDnQKjMWqt75XtT8+H3Qd2XOi6zRdbU1NRQe3p6uhpz+vTpoXbfbMbsVmMKf7Ib0wg2dmMaodPYI+IrEXE8Ih5e0LcxIg5HxJHB1w0XdprGmJWS8dm/CuBfAPzbgr79AO4rpRyIiP2D9h19JpAJdMlsdcxkkkOU38SJDsqPywTHZIJxVDWbjF/PCT2ZLbPUmEzlHHXcpk2bhtpqjfg4VRWW1yOzrbOC1yij+2TeDzUnNYaDaHh9gPpZq/vid0bpCuz789qvKKimlPJfAE5T9y0ADg2+PwTgk13nMcaMl74++9ZSyiwADL5OdYw3xoyZC/6nt4jYB2Dfhb6OMWZp+n6yz0XEDAAMvh5fbGAp5WAp5bpSynU9r2WMWQX6frLfA2AvgAODr3dnD+zK2FLCFotmvOUNUIs0fQMkMqWt+TzqWkrI4TlmgnrUevCclNCXEXu4THZmD3WgFpcyZaLVuTNjVlKZZSH8zqhnnxEIMxmOnImmrq8CwzJiNYuBLNYuVfkp86e3bwD4IYDfj4jnI+JWzBv5TRFxBMBNg7YxZoLp/GQvpXxmkf+6cZXnYoy5gDiCzphGmLhEmIzPrgJN2G9Wfj37yMq3yiTCZCrFqMSTX/7yl0NtFViRqYDLxynfv+sYIFfhZW5urrMvo1nwfak+NYZ1hbNnz1ZjuLrvyy+/XI3hPqVhqHXMVDbm45SGwr42B8cA9Xul3k+2hcz7ev78i/6PMeZ3Chu7MY1gYzemEWzsxjTCyAW6rkwrJdCxAKKEnMwe2SxuZAS6zL7mKhhDCSWZwB8W5DKZTydPnqzGZPaZz8zn+PE6OJKDX5QgxQKpEr+4LLISv1544YWh9lNPPVWNmZ2dHWqr58GVjDZu3FiNUaIuv1fq3eNnpsZwJtwzzzxTjWGUyNu1zZlLSRtjbOzGtIKN3ZhGsLEb0wgjF+hYUGARIhP5pgQQ5le/+lXVx0KSOg9HOimBikUjJeJlMp9UdNyGDcPl/NR6MKdOnar6Tpw4MdRWmWk8RzVntff8mTNnhtrqPjhiTUW18Rw5whCoBSe1P/r27duH2lu2bKnG8DuUKaMN5MqG8zushLV3vvOdQ20lhvIz6rvP4GL4k92YRrCxG9MINnZjGmHkPvtSWTmA9qX4GOUTsW+ngkjYJ1QBGnycyk7K+GgquCFTiYR9SxX8wVqDqnrCvpzyEfnc69evr8aoObLPrs7NmXEq8IcDRNSzZx2BfV+gXleeHwAcO3ZsyWMAHfiTqVzEATsqyCiTncZ96h3igCF1rcXwJ7sxjWBjN6YRbOzGNIKN3ZhGGHvWG6PErkz5JO5T5+HgFxWwwkE127Ztq8awkKJKPqmyyCwQKvGPg3iee+65zutngnpYRAJqQU6Jmkp843M9++yz1Ri+NyX0sdCoAnhYfFTP9cknnxxqq/vIiKObN2+u+nbs2DHUVoFHjHo/WdhTWZmZMl18Hm67LJUxxsZuTCvY2I1phJH67BHRWYZZVSvhQALl73AAggo04eSYzP7oyvdmH10FPyjfkn1J5VtyX6a0thrD59m6dWs1hvUJlYii4Osp7aGrogpQr63a15wTaFSCE9/r7t27qzHsa7Ofr86j+qam6g2LeR3V+5nRi/h9VLbApbT5PVfHnMOf7MY0go3dmEawsRvTCDZ2Yxph7JVqWKBTQQFK7GIy2T8sJCmxh6u+KPEps6+cChDh+1BZVtynKrwwSnzja6n74HLGaj4qy4uFNfXMODtNiV+ZjDZ+ruo+pqenh9qqmg0HZu3cubMao/pYNFTn5jlm9pTPlDFX4jDDa++gGmOMjd2YVrCxG9MIY69Uk6mWyYECyi9hv1n5ROx/qr3HM1VHMjqD8nXZJ8skOig9gDUDleSSqWiyZ8+eobZKBFEBQxx8o/ZM52CPzDqqCrh8r8qv5nVVATwc1KKq8qigHr6+eq6sjyifnddR6SOsIalr8b05EcYYU2FjN6YRbOzGNEKnsUfE1RHxnxHxaEQ8EhG3Dfo3RsThiDgy+Lqh61zGmPGREejeBPC5UsrPIuJKAD+NiMMA/hLAfaWUAxGxH8B+AHcsdaKI6BQUMlVoMmV4lbDFgpgSSTj4g/cQB3KVc5baJ/scSkhi1L2yIKXEL76+Ep+4CgtvowRokYiFJBVApLLKGL43lS22HAFqsWOAWsTkTLXFjuM5qTny+5DJgsxkd6r3oysobalKUJ1vWylltpTys8H3LwF4FMB2ALcAODQYdgjAJ7vOZYwZH8v601tE7ALwAQA/ArC1lDILzP9AiIg60Xf+mH0A9g2+X9FkjTH9SQt0EXEFgLsA3F5KqYPKF6GUcrCUcl0p5TobuzHjI/XJHhGXYN7Qv15K+fagey4iZgaf6jMA6r2NiTVr1lR+M/syyt/hhADl7/Bx6gcL+7aqKitXWFHVVdmvz/jnQO1vZeao/DYek9n+V20j1XVeQK8RP49du3ZVY9i3Vc+M+1SVXj5PJtAkUylGjVF9vLbKJ84E1fC9Zt5h9ewzYxYjo8YHgC8DeLSU8sUF/3UPgL2D7/cCuDt9VWPMyMl8sn8YwF8A+O+IeGjQ93cADgD4VkTcCuBZAJ+6IDM0xqwKncZeSvk+gMWc7RtXdzrGmAuFI+iMaYSRl5JmwYOFk77iBgtSKhiGM+FU4E1GEGKBSlXSUcJJJkAkExzEASLq+nz/SnxiQUyJT6oyCwfRqHOzIKhERD63yp7jykHq/eBzZ4S2jNCnUGvdtaWZGqOOyVw/I/Iuemx6pDHmosbGbkwj2NiNaYSR+uyllM6ggEyigaq6mfH9M5U4ObBE+czcp/y4TJ/yY7nCqkrWYVSVXF5XtWb8LJR/vmFDnczIPnsmqCjjR6vgHO5T1WxYn1CJORky24UrvSjjj/P7mKlmo9ZsJfiT3ZhGsLEb0wg2dmMawcZuTCOMvJT0SrJ2zqGyo7hPZWvxtdV5MtlzjNq2SJWJ5j4l/nGwhxKEWJDL7FmeuY9M9RSgXiM15syZM0NtJTbxnJRgyc9RrSsfp8qIZyoQZTLzlEDI66EESz6PEgMzQiev2apmvRljfjewsRvTCDZ2YxrBxm5MI4w8go6FiYxIwyhBiPuU2MJiT2bfdyX0sQCkBKFMiSd1ryzSZCLGeO81oN5rTZWSzkTZKWGtq5yxOldGkFICFZd8VuuaER8z2YzqPHxvmcjITDkpda+ZzLwuvNebMcbGbkwr2NiNaYSRV6rpqrSh/J3VqjefCQbJbPfDfhwHbAC5YIdMwIoK/mAfnf1zoN5rfXp6uhrD96b2Z1dBLBzEo/zod73rXUNtpaE8/fTTQ231nHmNlD6SKfec8Zkz2zZljlP3kdGHMvPpE4R2/tjeRxpjLips7MY0go3dmEawsRvTCCPPeuNAgT77b/cRO4Ba8Mjs26WEJRaE1JyVuJLZZ54FmIyI9+53v7saw3uvv/zyy9UYvrejR49WY+bm5qo+FuiUaMTlrtV6cMktzpQDcoJpBs5wzGSvqb6+AnKmbHeGzDu0GP5kN6YRbOzGNIKN3ZhGGHulmozvwn5rJvhB+VaZrXMy8+PzqPkoX1sFqDAZ35KDX1588cVqzIMPPjjUzpSJfuGFF6oxmSAOlUDD51L3sXv37qG22kO+z5ZMStPhdc1UhQFqjUC9D5l3mAOf1Bz7bA+2HN/fn+zGNIKN3ZhGsLEb0wg2dmMaYeQCHQsMmYyhTOAAC2JKuMiILV3HADnRKCP+KRGPM9pUJtrWrVuH2o899lg15oknnhhqq6o4LIgpgUxVS+E5Hjt2rBrD97Znz55qzHve856hthIRT5w4seR5gdxz7Ztd2ad0s5ojZy+qYC0uLZ6pnONS0saYChu7MY3QaewRcVlE/Dgifh4Rj0TEFwb9GyPicEQcGXyt9/Y1xkwMGZ/9NQA3lFJejohLAHw/Iv4dwJ8BuK+UciAi9gPYD+COpU4UEZUPmNnbmn0y5ctw0Ebf/a8z+8Wzb6Uq0Cpfiu9N+W1ciWXnzp3VGF7Da6+9thrD96r2LOfrq22kMslCal91royjknWmpqaG2qoKDXP27NnOMZm94LPJS7xG6rny9VSQ0enTp4faKsCKz5NJploOnZ/sZZ5zKVOXDP4VALcAODToPwTgk71nYYy54KR89ohYGxEPATgO4HAp5UcAtpZSZgFg8HVqiVMYY8ZMythLKW+VUt4PYAeAD0bE+7IXiIh9EfFARDyQjUc2xqw+y1LjSylnAdwP4GYAcxExAwCDr8cXOeZgKeW6Usp1K6mMaYxZGZ0CXURsAfBGKeVsRFwO4KMA/gnAPQD2Ajgw+Hp35oJdWwdlBKE+mXJALcpkgnUyZYlVBlNGRFRjtmzZsuS1gPrerrnmmmoM7xmvMuO4T5WtVvfPwTczMzPVmPXr1w+1uXKNQgmWHGijsudYEMtUAMp+8GSCaligzayjEugyAWZd21EtZRsZNX4GwKGIWIv53wS+VUq5NyJ+COBbEXErgGcBfCpxLmPMmOg09lLKLwB8QPSfAnDjhZiUMWb1sRNtTCOMPBGG4a2DMpVjM9VCuDLJYsd1ofxIrtSa2Z4ZqH0wFUTC/vipU6c6x6ggEq7cum3btmoMX5+TTgC9ZnwuvpZC+docIJPZRlk9D95+K7MdcrbiTEbn4T4VwMSo9zyjK3TNx1s2G2Ns7Ma0go3dmEawsRvTCGMX6Fi4USJNJgCCRRmVecSinTpvppqMEpsYJZSwkKaCL1gky+z9rgQyVZmmCxUco8RHFqBUwA4fp+bDYptaaxbNlPCZ2UOdn312D/XMdkt8vZMnT3aO6ZvR1qdyzvmx6ZHGmIsaG7sxjWBjN6YRRuqzr127tvIvOUCl77Y47O+o7X85iIQrzgC1L6WCONhPUn6k8r/Yb1RBLBxEw5VcgVozUAFEvN1QJsjoyiuvrMaoe+OKNurc/MzUWrNfr5JD+JlxdRugTrLJPI++22wr7YHfYaVh8DuT0QcUPO/lbHnuT3ZjGsHGbkwj2NiNaQQbuzGNMPKgGg4sYZFGZQyxAKSyvFjcUOfhcr6bNm3qPI+CRRol2iixieekgi9Y3FFBEyzQsUAE1PehtlbiOWbWFchV0+F7VcFBLCKqAB4WA1XgDR+n7jUjvKr7YMFLzfGpp54aavN9Abky2V3XXqwviz/ZjWkEG7sxjWBjN6YRxr5lcyawg/005Vuxb6sSYebm5obamaqomeolaozytblPXZ+3NlbrwfevAm/Y11XJO5nKKMpH5rVV+givo/JZWTPhY4Da1z9+vK5Y3mcL7eyWzRy0ou71yJEjQ22lfTAZbSjz7nEAkYNqjDE2dmNawcZuTCPY2I1phJEKdJn92ZX4xhlTmUokStzgQAqVdcaCmAqYYbFL7Rmuspr4XJm911VGGd9HJmBGCW18bhX4ouCtpZTQyJloah27MriAWrRTVXlYjFTiLJMRUFXfsWPHOq+fqYKjgq4yATMOqjHGdGJjN6YRbOzGNIKN3ZhGGHspac4iypROzpRJVlFMmWux2LZhw4bOc6sMKlUmmkUZJbbwvSmhj/uUiMeZcJnS2pk97YFcthxH9akx3KfKSbFop9aaz6MEXEaNUX281uq5ZvZb4/vIlEzPRNBl7vX8+dMjjTEXNTZ2YxrBxm5MI4zcZ2c/JFNyOLNtU8YnYn9PjeGsJhX8wIE3ytfN+FLKJ+M5qXtlP1L5sTwnla3Ffrw6T99S2rxuKhiGg3My5ZWV78/XVxl+Gb86s2e7ykLke1VrxlpMJjimz/7sS54vPdIYc1FjYzemEdLGHhFrI+LBiLh30N4YEYcj4sjga/03KmPMxLCcT/bbADy6oL0fwH2llD0A7hu0jTETSkqgi4gdAP4UwD8C+JtB9y0APjL4/hCA+wHc0XWuLuFKCTAs2mUEsUxZZFUWmEURldHWVQ4byJUBVnNkIUeJPSysqfXgrDMudwVosYlRZaq5NJTaVy+T5cXPQ90Hr5EScHlMJjgoW4KLj1Nrlik3zX1KHM6UO+P3PFPe6hzZT/YvAfg8gIVX2lpKmR1ccBZAveOeMWZi6DT2iPg4gOOllJ/2uUBE7IuIByLiAfWT0xgzGjK/xn8YwCci4mMALgNwVUR8DcBcRMyUUmYjYgZAXfYTQCnlIICDALBu3br87xzGmFWl09hLKXcCuBMAIuIjAP62lPLZiPhnAHsBHBh8vTtzwYxfwrB/pXwiRvnD7Ouq4ItMkguzdevWqk/5ZNyn7oN9W+Wjsl+v/M/p6emhNgewAPWzyPjMQF0ZZ9u2bdUY9vWV75+pVMPXV/PheWcCTbIBROyjq5LY/IwypcX7vPdAP/s5f770yJoDAG6KiCMAbhq0jTETyrLCZUsp92NedUcp5RSAG1d/SsaYC4Ej6IxpBBu7MY0w9ko1fYQKJcBkxvC1MtlaSkTjgBEVVJKpcKMq7rAAlNnHTAlLvM87702vrp9ZV6AWNtUYXkd1r1wpSI3JBN5k/qSbKZudCdhRY7jctXofGLXWfK3sfnRZ/MluTCPY2I1pBBu7MY0wcp+9K7ggUy0kW2WEYR9d+V/Kj2fYZ1eVW3lLIKD2SVVQDwefqDmyjqDW45VXXlnyvEBOw8hUylG+Ns8xs65Ke2BfW1XS5ftQ68rPQ22ZpebIeoAK6mF9QiV79dmPPZMIk9kL/hz+ZDemEWzsxjSCjd2YRrCxG9MIIxfouiptZCq8KDKVSLrKWKu+jGCoAm8yW0tltrFS1+frqeuz2KVERO5ToqKCr6eq0LDYpebI98aiIpAr/81rPTc3V43JlLbObMmUCYTKvMOZ7aeU+NaV9baUEOhPdmMawcZuTCPY2I1phJH67BHRuVXPcipv8LkXkgk2UEEUmequmeopqo+3YFK+3ZYtW5Y8Bqh9O6VP8HFKQ+B7y+gTQP3MMltdqTnycWr7J15HtR6zs7NLHgPU1XbVnFUwDr8j6j62b98+1OYkJKBOjlFzzDxXVSkniz/ZjWkEG7sxjWBjN6YRbOzGNMJIBbpSSiXCZLaz6RNUo8QeDqxQwSCZyjB8bnWtzB7yKoiFzzUzM1ONyWx3xAEqakzXs1gMfkbqOA7YUcEoLH6poBausMNbT6njWIwD6ueh5pypDKOe9caNG4fa119/fTWGxT8+BgA2b9481D558mQ15nvf+95Qm5+zg2qMMTZ2Y1rBxm5MI4w8qIb9q0xgRcZnZ19F+eObNm0aaqvABr5+ZutnNWcFn0sF9XBFmWeeeaYaw76d8lEzW0RlkjNUUFFm26bMFsXs16sEFtY1MgEzGS0mqw312baJ3zOgDoZRFWj5ud5+++3VmPvvv3+ofddddw211Rqew5/sxjSCjd2YRrCxG9MINnZjGiH6Zpn1uljECQBHAWwGUEcMTD4X47w959EwKXP+vVLKFvUfIzX28xeNeKCUct3IL7xCLsZ5e86j4WKYs3+NN6YRbOzGNMK4jP3gmK67Ui7GeXvOo2Hi5zwWn90YM3r8a7wxjTByY4+ImyPi8Yh4MiL2j/r6GSLiKxFxPCIeXtC3MSIOR8SRwdcN45wjExFXR8R/RsSjEfFIRNw26J/YeUfEZRHx44j4+WDOXxj0T+yczxERayPiwYi4d9Ce+DmP1NgjYi2AfwXwJwDeC+AzEfHeUc4hyVcB3Ex9+wHcV0rZA+C+QXuSeBPA50op1wL4EIC/GqztJM/7NQA3lFL+EMD7AdwcER/CZM/5HLcBeHRBe/LnXEoZ2T8A1wP47oL2nQDuHOUcljHXXQAeXtB+HMDM4PsZAI+Pe44d878bwE0Xy7wBrAPwMwB/NOlzBrAD8wZ9A4B7L5b3Y9S/xm8H8NyC9vODvouBraWUWQAYfJ0a83wWJSJ2AfgAgB9hwuc9+HX4IQDHARwupUz8nAF8CcDnASzMCZ70OY/c2FViuv8csIpExBUA7gJweyklt1PjGCmlvFVKeT/mPy0/GBHvG/OUliQiPg7geCnlp+Oey3IZtbE/D+DqBe0dAI6NeA59mYuIGQAYfK0rH46ZiLgE84b+9VLKtwfdEz9vACilnAVwP+a1kkme84cBfCIi/hfANwHcEBFfw2TPGcDojf0nAPZExO6IuBTApwHcM+I59OUeAHsH3+/FvE88McR8mZUvA3i0lPLFBf81sfOOiC0RsX7w/eUAPgrgMUzwnEspd5ZSdpRSdmH+/f2PUspnMcFzPs8YxI2PAXgCwFMA/n7cosUic/wGgFkAb2D+t5FbAWzCvChzZPB147jnSXP+Y8y7RL8A8NDg38cmed4A/gDAg4M5PwzgHwb9Eztnmv9H8P8C3cTP2RF0xjSCI+iMaQQbuzGNYGM3phFs7MY0go3dmEawsRvTCDZ2YxrBxm5MI/wfcNHaBsPrLbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# menggunakan model untuk mengklasifikasikan gambar kamar\n",
    "\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# masukkan file nama gambar \n",
    "path = '/home/vego/Documents/skripsi/program/dataset/uji/angry/S026_003_00000013.png'\n",
    "img = tf.keras.preprocessing.image.load_img(path, target_size=(48,48))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = tf.image.resize(x, [48,48])\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "classes={\n",
    "    0: 'Angry',\n",
    "    1: 'Contempt',\n",
    "    2: 'Disgust',\n",
    "    3: 'Fear',\n",
    "    4: 'Happy',\n",
    "    5: 'Sadness',\n",
    "    6: 'Surprise'\n",
    "}\n",
    "images = np.vstack([x])\n",
    "pred = model.predict(images)\n",
    "\n",
    "class_names = classes.values()\n",
    "class_name = list(class_names)\n",
    "\n",
    "result =class_name[np.argmax(pred)]\n",
    "print(path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['accuracy']\n",
    "val_acc=hist.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(train_acc))\n",
    "\n",
    "plt.plot(epochs,train_loss,'r', label='train_loss')\n",
    "plt.plot(epochs,val_loss,'b', label='val_loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,train_acc,'r', label='train_acc')\n",
    "plt.plot(epochs,val_acc,'b', label='val_acc')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24664d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
